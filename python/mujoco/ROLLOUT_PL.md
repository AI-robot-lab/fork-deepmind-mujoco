# Dokumentacja Rollout - MuJoCo dla Student√≥w

## PrzeglƒÖd modu≈Çu `rollout.py`

Modu≈Ç `rollout.py` dostarcza **wielowƒÖtkowy mechanizm do wykonywania wielu symulacji r√≥wnolegle**. Jest to zaawansowane narzƒôdzie wykorzystywane g≈Ç√≥wnie w:
- Uczeniu maszynowym (Machine Learning)
- Optymalizacji trajektorii
- Testowaniu robustness (odporno≈õci) kontroler√≥w
- Symulacjach Monte Carlo

---

## Po co rollout?

### Scenariusz: Chcesz przetestowaƒá kontroler

**Bez rollout (sekwencyjnie):**
```
Test 1: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10s
Test 2: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10s  
Test 3: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10s
Test 4: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10s
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Razem:  40 sekund
```

**Z rollout (r√≥wnolegle, 4 wƒÖtki):**
```
Test 1: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 
Test 2: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà]  } R√≥wnocze≈õnie
Test 3: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà]  
Test 4: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Razem:  ~10 sekund (4x szybciej!)
```

---

## Podstawy u≈ºycia

### 1. Prosty rollout - jedna trajektoria

**Cel:** Wykonanie symulacji z otwartƒÖ pƒôtlƒÖ (open-loop) - z g√≥ry okre≈õlone sterowanie

**Przyk≈Çad:**
```python
import mujoco
from mujoco import rollout
import numpy as np

# Za≈Çaduj model
model = mujoco.MjModel.from_xml_path('model/humanoid/humanoid.xml')
data = mujoco.MjData(model)

# Przygotuj rollout object (z 4 wƒÖtkami)
with rollout.Rollout(nthread=4) as r:
    # Stan poczƒÖtkowy (pozycje i prƒôdko≈õci)
    # Dla humanoid: 28 pozycji (qpos) + 27 prƒôdko≈õci (qvel)
    initial_state = np.zeros((1, model.nq + model.nv))  # 1 trajektoria
    # Mo≈ºesz ustawiƒá w≈Çasny stan poczƒÖtkowy:
    # initial_state[0, :model.nq] = custom_qpos
    # initial_state[0, model.nq:] = custom_qvel
    
    # Sygna≈Çy sterujƒÖce (otwarta pƒôtla)
    # Wymiar: [liczba_trajektorii, liczba_krok√≥w, liczba_si≈Çownik√≥w]
    nsteps = 100  # 100 krok√≥w symulacji
    control = np.zeros((1, nsteps, model.nu))  # 1 trajektoria, 100 krok√≥w, nu si≈Çownik√≥w
    
    # Przyk≈Çad: sinusoidalne sterowanie pierwszym si≈Çownikiem
    for step in range(nsteps):
        control[0, step, 0] = np.sin(2 * np.pi * step / 50)
    
    # WYKONAJ ROLLOUT
    # Funkcja zwraca: (state, sensordata)
    # state: [nbatch, nstep, nstate] - wszystkie stany w trajektorii
    # sensordata: [nbatch, nstep, nsensordata] - dane z sensor√≥w
    state, sensordata = r.rollout(
        model=model,
        data=data,
        initial_state=initial_state,
        control=control
    )
    
    print(f"Kszta≈Çt state: {state.shape}")  # (1, 100, nstate)
    print(f"Kszta≈Çt sensordata: {sensordata.shape}")  # (1, 100, nsensordata)
```

**Co siƒô sta≈Ço:**
1. Rollout wykona≈Ç 100 krok√≥w symulacji
2. W ka≈ºdym kroku zastosowa≈Ç odpowiedni sygna≈Ç sterujƒÖcy z `control`
3. Zapisa≈Ç stan (pozycje, prƒôdko≈õci) w ka≈ºdym kroku
4. Zapisa≈Ç dane z sensor√≥w w ka≈ºdym kroku
5. Zwr√≥ci≈Ç kompletnƒÖ trajektoriƒô

---

### 2. Wiele trajektorii r√≥wnolegle (batch rollout)

**Cel:** Wykonanie wielu r√≥≈ºnych symulacji jednocze≈õnie

**Przyk≈Çad: Testowanie 100 r√≥≈ºnych warunk√≥w poczƒÖtkowych**

```python
import mujoco
from mujoco import rollout
import numpy as np

model = mujoco.MjModel.from_xml_path('model/humanoid/humanoid.xml')
data = mujoco.MjData(model)

# PRZYPADEK U≈ªYCIA: Sprawd≈∫ jak robot radzi sobie z r√≥≈ºnymi pozycjami startowymi

nbatch = 100  # 100 r√≥≈ºnych trajektorii
nsteps = 200  # Ka≈ºda po 200 krok√≥w

with rollout.Rollout(nthread=8) as r:  # U≈ºyj 8 wƒÖtk√≥w
    # Stw√≥rz 100 r√≥≈ºnych stan√≥w poczƒÖtkowych
    initial_states = np.zeros((nbatch, model.nq + model.nv))
    
    for i in range(nbatch):
        # Losowe ma≈Çe perturbacje pozycji poczƒÖtkowej
        initial_states[i, :model.nq] = np.random.randn(model.nq) * 0.1
        initial_states[i, model.nq:] = np.random.randn(model.nv) * 0.1
    
    # Taki sam kontroler dla wszystkich (mo≈ºna te≈º r√≥≈ºne!)
    # Wymiar: [nbatch, nsteps, nu]
    # Je≈õli podasz [1, nsteps, nu], zostanie automatycznie powielone (broadcast)
    control = np.zeros((1, nsteps, model.nu))
    
    # Wykonaj wszystkie 100 trajektorii r√≥wnolegle
    states, sensordatas = r.rollout(
        model=model,
        data=data,
        initial_state=initial_states,  # [100, nstate]
        control=control                # [1, nsteps, nu] -> auto-broadcast do [100, nsteps, nu]
    )
    
    print(f"Wykonano {nbatch} trajektorii")
    print(f"Kszta≈Çt wynik√≥w: {states.shape}")  # (100, 200, nstate)
    
    # ANALIZA: Ile trajektorii zako≈Ñczy≈Ço siƒô "sukcesem"?
    # Definicja sukcesu: robot nie upad≈Ç (wysoko≈õƒá > 0.8m w ostatnim kroku)
    final_heights = states[:, -1, 2]  # Wysoko≈õƒá Z w ostatnim kroku ka≈ºdej trajektorii
    success_count = np.sum(final_heights > 0.8)
    success_rate = success_count / nbatch * 100
    
    print(f"Wsp√≥≈Çczynnik sukcesu: {success_rate:.1f}%")
    print(f"≈örednia ko≈Ñcowa wysoko≈õƒá: {final_heights.mean():.2f}m")
```

**Zalety:**
- ‚úÖ 100 symulacji w czasie niewiele d≈Çu≈ºszym ni≈º 1 symulacja
- ‚úÖ Statystyczna walidacja kontrolera
- ‚úÖ Znajdowanie edge cases (sytuacje graniczne)

---

## Zaawansowane u≈ºycie

### 3. R√≥≈ºne kontrolery dla ka≈ºdej trajektorii

**Przyk≈Çad: Por√≥wnanie r√≥≈ºnych parametr√≥w kontrolera PD**

```python
import mujoco
from mujoco import rollout
import numpy as np

model = mujoco.MjModel.from_xml_path('model/humanoid/humanoid.xml')
data = mujoco.MjData(model)

# Cel: Znajd≈∫ optymalne wzmocnienia PD dla stabilnego stania

# Test 50 r√≥≈ºnych kombinacji Kp i Kd
nbatch = 50
nsteps = 500

# R√≥≈ºne warto≈õci Kp i Kd do przetestowania
Kp_values = np.linspace(10, 200, nbatch)
Kd_values = np.linspace(1, 20, nbatch)

with rollout.Rollout(nthread=8) as r:
    # Stan poczƒÖtkowy (ten sam dla wszystkich)
    initial_state = np.zeros((1, model.nq + model.nv))
    initial_state[0, :7] = [0, 0, 1, 1, 0, 0, 0]  # Pozycja i orientacja tu≈Çowia
    
    # Przygotuj sterowanie dla ka≈ºdej trajektorii
    controls = np.zeros((nbatch, nsteps, model.nu))
    
    # Prosta symulacja regulatora PD (uproszczona - brak pe≈Çnego feedback)
    # W praktyce: trzeba by u≈ºyƒá callbacks, tu tylko demonstracja konceptu
    target_pos = np.zeros(model.nv)  # Docelowa pozycja (stanie prosto)
    
    for batch_idx in range(nbatch):
        Kp = Kp_values[batch_idx]
        Kd = Kd_values[batch_idx]
        
        # Dla uproszczenia: sta≈Çe sterowanie (w rzeczywisto≈õci trzeba feedback)
        # To tylko ilustracja - prawdziwy PD wymaga odczytu stanu w ka≈ºdym kroku
        controls[batch_idx, :, :] = 0.1 * Kp  # Uproszczenie!
    
    # Wykonaj rollout
    states, _ = r.rollout(
        model=model,
        data=data,
        initial_state=initial_state,
        control=controls  # [nbatch, nsteps, nu]
    )
    
    # Analiza: kt√≥ry zestaw parametr√≥w da≈Ç najlepsze wyniki?
    # Metryka: ≈õrednia wysoko≈õƒá przez ca≈Çy czas
    avg_heights = states[:, :, 2].mean(axis=1)  # [nbatch]
    
    best_idx = np.argmax(avg_heights)
    print(f"Najlepsze parametry:")
    print(f"  Kp = {Kp_values[best_idx]:.1f}")
    print(f"  Kd = {Kd_values[best_idx]:.1f}")
    print(f"  ≈örednia wysoko≈õƒá: {avg_heights[best_idx]:.2f}m")
```

---

### 4. U≈ºycie wielu modeli (r√≥≈ºne roboty r√≥wnocze≈õnie)

**Przyk≈Çad: Por√≥wnanie dw√≥ch r√≥≈ºnych projekt√≥w robota**

```python
import mujoco
from mujoco import rollout
import numpy as np

# Za≈Çaduj dwa r√≥≈ºne modele
model1 = mujoco.MjModel.from_xml_path('model/humanoid/humanoid.xml')
model2 = mujoco.MjModel.from_xml_path('model/humanoid/humanoid100.xml')  # Wariant

# UWAGA: Modele muszƒÖ mieƒá tƒô samƒÖ "sygnaturƒô rozmiaru" 
# (te same nq, nv, nu, etc.)

# Je≈õli modele sƒÖ r√≥≈ºne, musisz u≈ºyƒá sequence:
models = [model1, model2, model1, model2]  # 4 trajektorie: 2x model1, 2x model2
nbatch = len(models)

# Dane dla ka≈ºdego modelu
datas = [mujoco.MjData(m) for m in models]

nsteps = 100

with rollout.Rollout(nthread=4) as r:
    initial_states = np.zeros((nbatch, model1.nq + model1.nv))
    controls = np.zeros((1, nsteps, model1.nu))
    
    states, _ = r.rollout(
        model=models,   # Lista modeli
        data=datas,     # Lista danych
        initial_state=initial_states,
        control=controls
    )
    
    print("Por√≥wnanie modeli:")
    print(f"Model 1, traj 0: ko≈Ñcowa wysoko≈õƒá = {states[0, -1, 2]:.2f}m")
    print(f"Model 2, traj 1: ko≈Ñcowa wysoko≈õƒá = {states[1, -1, 2]:.2f}m")
```

---

## Najwa≈ºniejsze parametry

### `rollout()` - parametry funkcji

```python
state, sensordata = r.rollout(
    model=model,                    # MjModel lub lista MjModel
    data=data,                      # MjData lub lista MjData
    initial_state=initial_state,    # [nbatch, nstate] lub [1, nstate]
    control=control,                # [nbatch, nstep, nu] lub [1, nstep, nu]
    
    # Opcjonalne:
    control_spec=mujoco.mjtState.mjSTATE_CTRL.value,  # Co oznacza 'control'
    skip_checks=False,              # Pomi≈Ñ sprawdzanie kszta≈Çt√≥w (szybsze, ale ryzykowne)
    nstep=None,                     # Liczba krok√≥w (auto z control je≈õli None)
    initial_warmstart=None,         # PoczƒÖtkowe qfrc_warmstart [nbatch, nv]
    state=None,                     # Bufor wyj≈õciowy (alokuj sam je≈õli None)
    sensordata=None,                # Bufor wyj≈õciowy dla sensor√≥w
    chunk_size=None,                # Wielko≈õƒá chunk√≥w dla threadpool
)
```

**Wyja≈õnienie parametr√≥w:**

#### `initial_state` - Stan poczƒÖtkowy
```python
# Sk≈Çada siƒô z: [qpos, qvel]
# qpos: pozycje staw√≥w [nq]
# qvel: prƒôdko≈õci staw√≥w [nv]

initial_state = np.zeros((nbatch, model.nq + model.nv))
initial_state[:, :model.nq] = starting_qpos   # Ustaw pozycje
initial_state[:, model.nq:] = starting_qvel   # Ustaw prƒôdko≈õci
```

#### `control` - Sygna≈Çy sterujƒÖce
```python
# Wymiar: [nbatch lub 1, nstep, nu]
# Dla ka≈ºdej trajektorii, dla ka≈ºdego kroku, dla ka≈ºdego si≈Çownika

# Przyk≈Çad 1: Sta≈Çe sterowanie
control = np.ones((1, 100, model.nu)) * 0.5  # Wszystkie si≈Çowniki na 0.5

# Przyk≈Çad 2: R√≥≈ºne dla ka≈ºdej trajektorii
control = np.random.randn(nbatch, nsteps, model.nu)

# Przyk≈Çad 3: Zmienne w czasie
control = np.zeros((1, nsteps, model.nu))
for t in range(nsteps):
    control[0, t, :] = np.sin(2*np.pi*t/nsteps)  # Sinusoida
```

#### `control_spec` - Interpretacja sterowania
```python
# Domy≈õlnie: mjSTATE_CTRL (sterowanie si≈Çownikami)
# Mo≈ºliwe opcje:
# - mjSTATE_CTRL: control to warto≈õci dla actuators (domy≈õlne)
# - mjSTATE_QFRC_APPLIED: control to bezpo≈õrednie si≈Çy w stawach
```

---

## Praktyczne zastosowania dla student√≥w

### 1. Uczenie przez wzmacnianie (Reinforcement Learning)

```python
"""
Rollout u≈ºywany do zbierania do≈õwiadcze≈Ñ (experiences) dla RL.
"""

# Generuj trajektorie z losowym sterowaniem (exploration)
nbatch = 1000  # 1000 trajektorii
nsteps = 50

initial_states = sample_initial_states(nbatch)  # Twoja funkcja
random_actions = np.random.uniform(-1, 1, (nbatch, nsteps, model.nu))

with rollout.Rollout(nthread=16) as r:
    states, sensors = r.rollout(model, data, initial_states, random_actions)
    
    # Oblicz nagrody (rewards)
    rewards = compute_rewards(states)  # Twoja funkcja
    
    # Zapisz do replay buffer
    add_to_buffer(states, random_actions, rewards)
```

### 2. Optymalizacja trajektorii

```python
"""
Znajd≈∫ najlepszƒÖ trajektoriƒô metodƒÖ pr√≥bkowania (sampling-based).
"""

def optimize_trajectory(model, data, target_position, n_iterations=10):
    """
    Prosta optymalizacja: pr√≥bkuj losowe sterowania i wybierz najlepsze.
    """
    best_control = None
    best_cost = float('inf')
    
    with rollout.Rollout(nthread=8) as r:
        for iteration in range(n_iterations):
            # Pr√≥bkuj 100 kandydat√≥w
            candidate_controls = np.random.randn(100, 50, model.nu)
            
            # Ewaluuj wszystkie
            states, _ = r.rollout(
                model, data,
                initial_state=np.zeros((1, model.nq + model.nv)),
                control=candidate_controls
            )
            
            # Oblicz koszty
            final_positions = states[:, -1, :3]  # Ko≈Ñcowe pozycje XYZ
            costs = np.linalg.norm(final_positions - target_position, axis=1)
            
            # Znajd≈∫ najlepszego
            min_idx = np.argmin(costs)
            if costs[min_idx] < best_cost:
                best_cost = costs[min_idx]
                best_control = candidate_controls[min_idx]
                print(f"Iteracja {iteration}: Nowy najlepszy koszt = {best_cost:.3f}")
    
    return best_control

# U≈ºycie
target = np.array([1.0, 0.0, 1.0])  # Docelowa pozycja XYZ
optimal_control = optimize_trajectory(model, data, target)
```

### 3. Testowanie odporno≈õci (robustness testing)

```python
"""
Sprawd≈∫ jak kontroler radzi sobie z perturbacjami.
"""

# Test: jak wp≈ÇywajƒÖ ma≈Çe zmiany w masie robota?
nbatch = 20
mass_variations = np.linspace(0.8, 1.2, nbatch)  # ¬±20% masy

# Stw√≥rz warianty modelu
models = []
for mass_factor in mass_variations:
    m = mujoco.MjModel.from_xml_path('model/humanoid/humanoid.xml')
    m.body_mass[:] *= mass_factor  # Przeskaluj masy
    models.append(m)

datas = [mujoco.MjData(m) for m in models]

# Taki sam kontroler dla wszystkich
controller_output = np.zeros((1, 200, model.nu))  # Tw√≥j kontroler

with rollout.Rollout(nthread=8) as r:
    states, _ = r.rollout(models, datas, 
                           initial_state=np.zeros((1, model.nq + model.nv)),
                           control=controller_output)
    
    # Analiza: jak masa wp≈Çywa na stabilno≈õƒá?
    final_heights = states[:, -1, 2]
    
    import matplotlib.pyplot as plt
    plt.plot(mass_variations, final_heights, 'o-')
    plt.xlabel('Wsp√≥≈Çczynnik masy')
    plt.ylabel('Ko≈Ñcowa wysoko≈õƒá [m]')
    plt.title('Wp≈Çyw masy na stabilno≈õƒá')
    plt.grid(True)
    plt.savefig('robustness_test.png')
```

---

## R√≥≈ºnice: rollout vs normalna pƒôtla symulacji

### Normalna pƒôtla (zamkniƒôta):
```python
# PƒòTLA ZAMKNIƒòTA (closed-loop)
# Kontroler ma dostƒôp do stanu w ka≈ºdym kroku

for step in range(nsteps):
    # 1. Odczytaj aktualny stan
    current_state = data.qpos, data.qvel
    
    # 2. Oblicz sterowanie NA PODSTAWIE aktualnego stanu
    data.ctrl[:] = controller(current_state)  # Feedback!
    
    # 3. Krok symulacji
    mujoco.mj_step(model, data)
```

### Rollout (otwarta):
```python
# PƒòTLA OTWARTA (open-loop)  
# Sterowanie jest z g√≥ry okre≈õlone, bez feedback

# 1. Przygotuj WSZYSTKIE sygna≈Çy sterujƒÖce z g√≥ry
all_controls = np.zeros((1, nsteps, model.nu))
for step in range(nsteps):
    all_controls[0, step, :] = precomputed_control(step)  # Brak feedback!

# 2. Wykonaj ca≈ÇƒÖ trajektoriƒô na raz
states, _ = rollout.rollout(model, data, initial_state, all_controls)
```

**Kiedy co u≈ºywaƒá?**
- **Normalna pƒôtla**: Gdy potrzebujesz feedback (wiƒôkszo≈õƒá kontroler√≥w)
- **Rollout**: Gdy:
  - Testujesz wielu kandydat√≥w r√≥wnocze≈õnie
  - Masz z g√≥ry okre≈õlonƒÖ trajektoriƒô
  - Optymalizujesz open-loop sterowanie
  - Zbierasz dane do ML

---

## Optymalizacja wydajno≈õci

### Tipsy dla maksymalnej szybko≈õci:

```python
# 1. U≈ºyj odpowiedniej liczby wƒÖtk√≥w
import os
n_cores = os.cpu_count()
with rollout.Rollout(nthread=n_cores) as r:  # Wykorzystaj wszystkie rdzenie
    ...

# 2. Pomi≈Ñ sprawdzanie kszta≈Çt√≥w (je≈õli jeste≈õ pewien)
states, _ = r.rollout(..., skip_checks=True)

# 3. Pre-alokuj bufory wyj≈õciowe
state_buffer = np.zeros((nbatch, nsteps, model.nq + model.nv))
sensor_buffer = np.zeros((nbatch, nsteps, model.nsensordata))

states, sensors = r.rollout(
    ...,
    state=state_buffer,      # U≈ºyj istniejƒÖcego bufora
    sensordata=sensor_buffer
)

# 4. U≈ºyj wiƒôkszych chunk_size dla du≈ºych batch
# Domy≈õlnie: chunk_size = max(1, nbatch / (nthread * 10))
# Dla bardzo du≈ºych nbatch, zwiƒôksz:
states, _ = r.rollout(..., chunk_size=100)
```

---

## Typowe b≈Çƒôdy

### 1. Z≈Çe wymiary tablicy control

```python
# B≈ÅƒÑD: Zapomnia≈Çe≈õ o wymiarze batch
control = np.zeros((nsteps, model.nu))  # ‚ùå Brak wymiaru batch!

# POPRAWNIE:
control = np.zeros((1, nsteps, model.nu))  # ‚úÖ [batch, steps, nu]
# lub
control = np.zeros((nbatch, nsteps, model.nu))
```

### 2. Niezgodne rozmiary miƒôdzy model a initial_state

```python
# B≈ÅƒÑD: ≈πle policzone nstate
initial_state = np.zeros((nbatch, model.nq))  # ‚ùå Brak qvel!

# POPRAWNIE:
nstate = model.nq + model.nv  # qpos + qvel
initial_state = np.zeros((nbatch, nstate))  # ‚úÖ
```

### 3. Pr√≥ba u≈ºycia feedback w rollout

```python
# To NIE ZADZIA≈ÅA - rollout to open-loop!
# Nie mo≈ºesz u≈ºyƒá aktualnego stanu do obliczenia kontroli

for step in range(nsteps):
    control[0, step, :] = pd_controller(current_state)  # ‚ùå Nie masz current_state!
```

---

## Podsumowanie

### Kluczowe punkty:

‚úÖ **Rollout = wielowƒÖtkowa symulacja open-loop**  
‚úÖ **Idealny do: ML, optymalizacji, testowania robustness**  
‚úÖ **NIE do: kontroler√≥w wymagajƒÖcych feedback w ka≈ºdym kroku**  
‚úÖ **Znaczne przy≈õpieszenie przy wielu trajektoriach**  

### Zalecane ≈õcie≈ºki nauki:

1. **PoczƒÖtkujƒÖcy:** Zacznij od 1 trajektorii, zrozum wymiary tablic
2. **≈öredni:** U≈ºyj wielu trajektorii do testowania r√≥≈ºnych warunk√≥w
3. **Zaawansowany:** Zintegruj z algorytmami ML (RL, optymalizacja)

---

**Dokumentacja przygotowana dla student√≥w Politechniki Rzeszowskiej** üéì
